#!/usr/bin/env python3

import argparse, cv2, numpy as np, pathlib, textwrap
import statistics
from collections import defaultdict

from core_encoder import *
from gop_processor import generate_gop_unified_codebooks
from dither_opt import apply_dither_optimized

class EncodingStats:
    """ç¼–ç ç»Ÿè®¡ç±»"""
    def __init__(self):
        # å¸§ç»Ÿè®¡
        self.total_frames_processed = 0
        self.total_i_frames = 0
        self.forced_i_frames = 0  # å¼ºåˆ¶Iå¸§ï¼ˆGOPå¼€å§‹ï¼‰
        self.threshold_i_frames = 0  # è¶…é˜ˆå€¼Iå¸§
        self.total_p_frames = 0
        
        # å¤§å°ç»Ÿè®¡
        self.total_i_frame_bytes = 0
        self.total_p_frame_bytes = 0
        self.total_codebook_bytes = 0  # åªè®¡ç®—Iå¸§ä¸­çš„ç æœ¬æ•°æ®
        self.total_index_bytes = 0     # åªè®¡ç®—Iå¸§ä¸­çš„ç´¢å¼•æ•°æ®
        self.total_p_overhead_bytes = 0  # På¸§çš„å¼€é”€æ•°æ®ï¼ˆbitmapç­‰ï¼‰
        
        # På¸§å—æ›´æ–°ç»Ÿè®¡
        self.p_frame_updates = []  # æ¯ä¸ªPå¸§çš„æ›´æ–°å—æ•°
        self.zone_usage = defaultdict(int)  # åŒºåŸŸä½¿ç”¨æ¬¡æ•°
        
        # ç»†èŠ‚ç»Ÿè®¡
        self.color_block_bytes = 0
        self.detail_block_bytes = 0
        self.color_update_count = 0
        self.detail_update_count = 0
        
        # ç è¡¨ä½¿ç”¨ç»Ÿè®¡
        self.small_codebook_updates = 0      # å°ç è¡¨æ›´æ–°æ¬¡æ•°
        self.medium_codebook_updates = 0     # ä¸­ç è¡¨æ›´æ–°æ¬¡æ•°
        self.full_codebook_updates = 0       # å¤§ç è¡¨æ›´æ–°æ¬¡æ•°
        self.small_codebook_bytes = 0        # å°ç è¡¨æ•°æ®å¤§å°
        self.medium_codebook_bytes = 0       # ä¸­ç è¡¨æ•°æ®å¤§å°
        self.full_codebook_bytes = 0         # å¤§ç è¡¨æ•°æ®å¤§å°
        
        # ç è¡¨æ®µä½¿ç”¨ç»Ÿè®¡
        self.small_segment_usage = defaultdict(int)  # å°ç è¡¨å„æ®µä½¿ç”¨æ¬¡æ•°
        self.medium_segment_usage = defaultdict(int) # ä¸­ç è¡¨å„æ®µä½¿ç”¨æ¬¡æ•°
        
        # ç è¡¨æ•ˆç‡ç»Ÿè®¡
        self.small_codebook_blocks_per_update = []  # æ¯æ¬¡å°ç è¡¨æ›´æ–°çš„å—æ•°
        self.medium_codebook_blocks_per_update = [] # æ¯æ¬¡ä¸­ç è¡¨æ›´æ–°çš„å—æ•°
        self.full_codebook_blocks_per_update = []   # æ¯æ¬¡å¤§ç è¡¨æ›´æ–°çš„å—æ•°
    
    def add_i_frame(self, size_bytes, is_forced=True, codebook_size=0, index_size=0):
        self.total_frames_processed += 1
        self.total_i_frames += 1
        if is_forced:
            self.forced_i_frames += 1
        else:
            self.threshold_i_frames += 1
        
        self.total_i_frame_bytes += size_bytes
        self.total_codebook_bytes += codebook_size
        self.total_index_bytes += index_size
    
    def add_p_frame(self, size_bytes, updates_count, zone_count, 
                   color_updates=0, detail_updates=0,
                   small_updates=0, medium_updates=0, full_updates=0,
                   small_bytes=0, medium_bytes=0, full_bytes=0,
                   small_segments=None, medium_segments=None,
                   small_blocks_per_update=None, medium_blocks_per_update=None, full_blocks_per_update=None):
        self.total_frames_processed += 1
        self.total_p_frames += 1
        self.total_p_frame_bytes += size_bytes
        self.p_frame_updates.append(updates_count)
        self.zone_usage[zone_count] += 1
        
        # På¸§å¼€é”€ï¼šå¸§ç±»å‹(1) + bitmap(2) + æ¯ä¸ªåŒºåŸŸçš„è®¡æ•°(2*zones)
        overhead = 3 + zone_count * 2
        self.total_p_overhead_bytes += overhead
        
        self.color_update_count += color_updates
        self.detail_update_count += detail_updates
        
        # ç è¡¨ä½¿ç”¨ç»Ÿè®¡
        self.small_codebook_updates += small_updates
        self.medium_codebook_updates += medium_updates
        self.full_codebook_updates += full_updates
        self.small_codebook_bytes += small_bytes
        self.medium_codebook_bytes += medium_bytes
        self.full_codebook_bytes += full_bytes
        
        # æ®µä½¿ç”¨ç»Ÿè®¡
        if small_segments:
            for seg_idx, count in small_segments.items():
                self.small_segment_usage[seg_idx] += count
        if medium_segments:
            for seg_idx, count in medium_segments.items():
                self.medium_segment_usage[seg_idx] += count
        
        # æ•ˆç‡ç»Ÿè®¡
        if small_blocks_per_update:
            self.small_codebook_blocks_per_update.extend(small_blocks_per_update)
        if medium_blocks_per_update:
            self.medium_codebook_blocks_per_update.extend(medium_blocks_per_update)
        if full_blocks_per_update:
            self.full_codebook_blocks_per_update.extend(full_blocks_per_update)
    
    def print_summary(self, total_frames, total_bytes):
        print(f"\nğŸ“Š ç¼–ç ç»Ÿè®¡æŠ¥å‘Š")
        print(f"=" * 60)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ¬ å¸§ç»Ÿè®¡:")
        print(f"   è§†é¢‘å¸§æ•°: {total_frames}")
        print(f"   Iå¸§: {self.total_i_frames} ({self.total_i_frames/total_frames*100:.1f}%)")
        print(f"     - å¼ºåˆ¶Iå¸§: {self.forced_i_frames}")
        print(f"     - è¶…é˜ˆå€¼Iå¸§: {self.threshold_i_frames}")
        print(f"   På¸§: {self.total_p_frames} ({self.total_p_frames/total_frames*100:.1f}%)")
        
        # å¤§å°ç»Ÿè®¡
        print(f"\nğŸ’¾ ç©ºé—´å ç”¨:")
        print(f"   æ€»å¤§å°: {total_bytes:,} bytes ({total_bytes/1024:.1f} KB)")
        print(f"   Iå¸§æ•°æ®: {self.total_i_frame_bytes:,} bytes ({self.total_i_frame_bytes/total_bytes*100:.1f}%)")
        print(f"   På¸§æ•°æ®: {self.total_p_frame_bytes:,} bytes ({self.total_p_frame_bytes/total_bytes*100:.1f}%)")
        
        if self.total_i_frames > 0:
            print(f"   å¹³å‡Iå¸§å¤§å°: {self.total_i_frame_bytes/self.total_i_frames:.1f} bytes")
        if self.total_p_frames > 0:
            print(f"   å¹³å‡På¸§å¤§å°: {self.total_p_frame_bytes/self.total_p_frames:.1f} bytes")
        
        # æ•°æ®æ„æˆç»Ÿè®¡
        print(f"\nğŸ¨ æ•°æ®æ„æˆ:")
        print(f"   ç æœ¬æ•°æ®: {self.total_codebook_bytes:,} bytes ({self.total_codebook_bytes/total_bytes*100:.1f}%)")
        print(f"   Iå¸§ç´¢å¼•: {self.total_index_bytes:,} bytes ({self.total_index_bytes/total_bytes*100:.1f}%)")
        
        # På¸§æ•°æ®æ„æˆ
        p_frame_data_bytes = self.total_p_frame_bytes - self.total_p_overhead_bytes
        print(f"   På¸§æ›´æ–°æ•°æ®: {p_frame_data_bytes:,} bytes ({p_frame_data_bytes/total_bytes*100:.1f}%)")
        print(f"   På¸§å¼€é”€: {self.total_p_overhead_bytes:,} bytes ({self.total_p_overhead_bytes/total_bytes*100:.1f}%)")
        
        # ç è¡¨ä½¿ç”¨ç»Ÿè®¡
        total_detail_updates = self.small_codebook_updates + self.medium_codebook_updates + self.full_codebook_updates
        if total_detail_updates > 0:
            print(f"\nğŸ“š ç è¡¨ä½¿ç”¨åˆ†æ:")
            print(f"   å°ç è¡¨æ›´æ–°: {self.small_codebook_updates:,} æ¬¡ ({self.small_codebook_updates/total_detail_updates*100:.1f}%)")
            print(f"   ä¸­ç è¡¨æ›´æ–°: {self.medium_codebook_updates:,} æ¬¡ ({self.medium_codebook_updates/total_detail_updates*100:.1f}%)")
            print(f"   å¤§ç è¡¨æ›´æ–°: {self.full_codebook_updates:,} æ¬¡ ({self.full_codebook_updates/total_detail_updates*100:.1f}%)")
            
            print(f"\nğŸ’¾ ç è¡¨æ•°æ®å¤§å°:")
            total_codebook_data = self.small_codebook_bytes + self.medium_codebook_bytes + self.full_codebook_bytes
            if total_codebook_data > 0:
                print(f"   å°ç è¡¨æ•°æ®: {self.small_codebook_bytes:,} bytes ({self.small_codebook_bytes/total_codebook_data*100:.1f}%)")
                print(f"   ä¸­ç è¡¨æ•°æ®: {self.medium_codebook_bytes:,} bytes ({self.medium_codebook_bytes/total_codebook_data*100:.1f}%)")
                print(f"   å¤§ç è¡¨æ•°æ®: {self.full_codebook_bytes:,} bytes ({self.full_codebook_bytes/total_codebook_data*100:.1f}%)")
            
            # ç è¡¨æ•ˆç‡ç»Ÿè®¡
            if self.small_codebook_blocks_per_update:
                avg_small_blocks = statistics.mean(self.small_codebook_blocks_per_update)
                print(f"   å°ç è¡¨å¹³å‡æ¯æ¬¡æ›´æ–°å—æ•°: {avg_small_blocks:.1f}")
            if self.medium_codebook_blocks_per_update:
                avg_medium_blocks = statistics.mean(self.medium_codebook_blocks_per_update)
                print(f"   ä¸­ç è¡¨å¹³å‡æ¯æ¬¡æ›´æ–°å—æ•°: {avg_medium_blocks:.1f}")
            if self.full_codebook_blocks_per_update:
                avg_full_blocks = statistics.mean(self.full_codebook_blocks_per_update)
                print(f"   å¤§ç è¡¨å¹³å‡æ¯æ¬¡æ›´æ–°å—æ•°: {avg_full_blocks:.1f}")
        
        # æ®µä½¿ç”¨ç»Ÿè®¡
        if self.small_segment_usage:
            print(f"\nğŸ”¢ å°ç è¡¨æ®µä½¿ç”¨åˆ†å¸ƒ:")
            total_small_updates = sum(self.small_segment_usage.values())
            for seg_idx in sorted(self.small_segment_usage.keys()):
                usage_count = self.small_segment_usage[seg_idx]
                if self.small_codebook_updates > 0:
                    print(f"   æ®µ{seg_idx}: {usage_count}æ¬¡ ({usage_count/self.small_codebook_updates*100:.1f}%)")
            
            # éªŒè¯æ’åºæ•ˆæœï¼šå‰4æ®µåº”è¯¥å å¤§éƒ¨åˆ†ä½¿ç”¨
            if total_small_updates > 0:
                first_4_segments_usage = sum(self.small_segment_usage.get(i, 0) for i in range(4))
                first_4_percentage = first_4_segments_usage / total_small_updates * 100
                print(f"   å‰4æ®µä½¿ç”¨ç‡: {first_4_percentage:.1f}% (æ’åºæ•ˆæœæŒ‡æ ‡)")
        
        if self.medium_segment_usage:
            print(f"\nğŸ”¢ ä¸­ç è¡¨æ®µä½¿ç”¨åˆ†å¸ƒ:")
            total_medium_updates = sum(self.medium_segment_usage.values())
            for seg_idx in sorted(self.medium_segment_usage.keys()):
                usage_count = self.medium_segment_usage[seg_idx]
                if self.medium_codebook_updates > 0:
                    print(f"   æ®µ{seg_idx}: {usage_count}æ¬¡ ({usage_count/self.medium_codebook_updates*100:.1f}%)")
            
            # éªŒè¯æ’åºæ•ˆæœï¼šå‰2æ®µåº”è¯¥å å¤§éƒ¨åˆ†ä½¿ç”¨
            if total_medium_updates > 0:
                first_2_segments_usage = sum(self.medium_segment_usage.get(i, 0) for i in range(2))
                first_2_percentage = first_2_segments_usage / total_medium_updates * 100
                print(f"   å‰2æ®µä½¿ç”¨ç‡: {first_2_percentage:.1f}% (æ’åºæ•ˆæœæŒ‡æ ‡)")
        
        # På¸§æ›´æ–°ç»Ÿè®¡
        if self.p_frame_updates:
            avg_updates = statistics.mean(self.p_frame_updates)
            median_updates = statistics.median(self.p_frame_updates)
            max_updates = max(self.p_frame_updates)
            min_updates = min(self.p_frame_updates)
            
            print(f"\nâš¡ På¸§æ›´æ–°åˆ†æ:")
            print(f"   å¹³å‡æ›´æ–°å—æ•°: {avg_updates:.1f}")
            print(f"   ä¸­ä½æ•°æ›´æ–°å—æ•°: {median_updates}")
            print(f"   æœ€å¤§æ›´æ–°å—æ•°: {max_updates}")
            print(f"   æœ€å°æ›´æ–°å—æ•°: {min_updates}")
            print(f"   è‰²å—æ›´æ–°æ€»æ•°: {self.color_update_count:,}")
            print(f"   çº¹ç†å—æ›´æ–°æ€»æ•°: {self.detail_update_count:,}")
        
        # åŒºåŸŸä½¿ç”¨ç»Ÿè®¡
        if self.zone_usage:
            print(f"\nğŸ—ºï¸  åŒºåŸŸä½¿ç”¨åˆ†å¸ƒ:")
            for zone_count in sorted(self.zone_usage.keys()):
                frames_count = self.zone_usage[zone_count]
                if self.total_p_frames > 0:
                    print(f"   {zone_count}ä¸ªåŒºåŸŸ: {frames_count}æ¬¡ ({frames_count/self.total_p_frames*100:.1f}%)")
        
        # å‹ç¼©æ•ˆç‡
        raw_size = total_frames * WIDTH * HEIGHT * 2  # å‡è®¾16ä½åƒç´ 
        compression_ratio = raw_size / total_bytes if total_bytes > 0 else 0
        print(f"\nğŸ“ˆ å‹ç¼©æ•ˆç‡:")
        print(f"   åŸå§‹å¤§å°ä¼°ç®—: {raw_size:,} bytes ({raw_size/1024/1024:.1f} MB)")
        print(f"   å‹ç¼©æ¯”: {compression_ratio:.1f}:1")
        print(f"   å‹ç¼©ç‡: {(1-total_bytes/raw_size)*100:.1f}%")

def main():
    pa = argparse.ArgumentParser(description="Encode to GBA YUV9 with unified codebook")
    pa.add_argument("input")
    pa.add_argument("--duration", type=float, default=5.0)
    pa.add_argument("--full-duration", action="store_true")
    pa.add_argument("--fps", type=int, default=30)
    pa.add_argument("--out", default="video_data")
    pa.add_argument("--i-frame-interval", type=int, default=60)
    pa.add_argument("--diff-threshold", type=float, default=2.0)
    pa.add_argument("--force-i-threshold", type=float, default=0.7)
    pa.add_argument("--variance-threshold", type=float, default=5.0,
                   help="æ–¹å·®é˜ˆå€¼ï¼Œç”¨äºåŒºåˆ†çº¯è‰²å—å’Œçº¹ç†å—ï¼ˆé»˜è®¤5.0ï¼‰")
    pa.add_argument("--codebook-size", type=int, default=DEFAULT_UNIFIED_CODEBOOK_SIZE,
                   help=f"ç»Ÿä¸€ç æœ¬å¤§å°ï¼ˆé»˜è®¤{DEFAULT_UNIFIED_CODEBOOK_SIZE}ï¼‰")
    pa.add_argument("--kmeans-max-iter", type=int, default=200)
    pa.add_argument("--threads", type=int, default=None)
    pa.add_argument("--i-frame-weight", type=int, default=3,
                   help="Iå¸§å—åœ¨èšç±»ä¸­çš„æƒé‡å€æ•°ï¼ˆé»˜è®¤3ï¼‰")
    pa.add_argument("--max-workers", type=int, default=None,
                   help="GOPå¤„ç†çš„æœ€å¤§è¿›ç¨‹æ•°ï¼ˆé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°-1ï¼‰")
    pa.add_argument("--dither", action="store_true",
                   help="å¯ç”¨Floyd-SteinbergæŠ–åŠ¨ç®—æ³•æå‡ç”»è´¨")
    pa.add_argument("--enabled-segments-bitmap", type=int, default=DEFAULT_ENABLED_SEGMENTS_BITMAP,
                   help=f"å¯ç”¨æ®µçš„bitmapï¼Œæ¯ä½è¡¨ç¤ºå¯¹åº”æ®µæ˜¯å¦å¯ç”¨å°ç è¡¨æ¨¡å¼ï¼ˆé»˜è®¤0x{DEFAULT_ENABLED_SEGMENTS_BITMAP:04X}ï¼‰")
    pa.add_argument("--enabled-medium-segments-bitmap", type=int, default=DEFAULT_ENABLED_MEDIUM_SEGMENTS_BITMAP,
                   help=f"å¯ç”¨ä¸­ç è¡¨æ®µçš„bitmapï¼Œæ¯ä½è¡¨ç¤ºå¯¹åº”æ®µæ˜¯å¦å¯ç”¨ä¸­ç è¡¨æ¨¡å¼ï¼ˆé»˜è®¤0x{DEFAULT_ENABLED_MEDIUM_SEGMENTS_BITMAP:02X}ï¼‰")
    args = pa.parse_args()

    cap = cv2.VideoCapture(args.input)
    if not cap.isOpened():
        raise SystemExit("âŒ æ‰“ä¸å¼€è¾“å…¥æ–‡ä»¶")

    src_fps = cap.get(cv2.CAP_PROP_FPS) or 30
    # è®¡ç®—å®é™…è¾“å‡ºFPSï¼šå¦‚æœç›®æ ‡FPSé«˜äºæºFPSï¼Œä½¿ç”¨æºFPS
    actual_output_fps = min(args.fps, src_fps)
    every = int(round(src_fps / actual_output_fps))
    
    if args.full_duration:
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        grab_max = total_frames
        actual_duration = total_frames / src_fps
        print(f"ç¼–ç æ•´ä¸ªè§†é¢‘: {total_frames} å¸§ï¼Œæ—¶é•¿ {actual_duration:.2f} ç§’")
    else:
        grab_max = int(args.duration * src_fps)
        print(f"ç¼–ç æ—¶é•¿: {args.duration} ç§’ ({grab_max} å¸§)")

    print(f"æºè§†é¢‘FPS: {src_fps:.2f}, ç›®æ ‡FPS: {args.fps}, å®é™…è¾“å‡ºFPS: {actual_output_fps:.2f}")
    print(f"ç æœ¬é…ç½®: ç»Ÿä¸€ç æœ¬{args.codebook_size}é¡¹")
    if args.dither:
        print(f"ğŸ¨ å·²å¯ç”¨æŠ–åŠ¨ç®—æ³•ï¼ˆè›‡å½¢æ‰«æï¼‰")
    
    frames = []
    idx = 0
    print("æ­£åœ¨æå–å¸§...")
    
    while idx < grab_max:
        ret, frm = cap.read()
        if not ret:
            break
        if idx % every == 0:
            frm = cv2.resize(frm, (WIDTH, HEIGHT), cv2.INTER_AREA)
            frm = cv2.GaussianBlur(frm, (3, 3), 0.41)
            if args.dither:
                frm = apply_dither_optimized(frm)
            
            frame_blocks = pack_yuv420_frame(frm)
            frames.append(frame_blocks)
            
            if len(frames) % 30 == 0:
                print(f"  å·²æå– {len(frames)} å¸§")
        idx += 1
    cap.release()

    if not frames:
        raise SystemExit("âŒ æ²¡æœ‰ä»»ä½•å¸§è¢«é‡‡æ ·")

    print(f"æ€»å…±æå–äº† {len(frames)} å¸§")

    # ç”Ÿæˆç»Ÿä¸€ç æœ¬ï¼ˆä¼ å…¥max_workerså‚æ•°ï¼‰
    gop_codebooks = generate_gop_unified_codebooks(
        frames, args.i_frame_interval, 
        args.variance_threshold, args.diff_threshold, args.codebook_size, 
        args.kmeans_max_iter, args.i_frame_weight, args.max_workers
    )

    # åŸºäº GOP å†… P å¸§çº¹ç†å—ä½¿ç”¨é¢‘æ¬¡ï¼Œå¯¹æ¯ä¸ªç æœ¬é¡¹é™åºé‡æ’
    import numpy as _np
    print("æ­£åœ¨æ ¹æ®ä½¿ç”¨é¢‘æ¬¡å¯¹ç æœ¬è¿›è¡Œæ’åº...")
    
    for gop_start, gop_data in gop_codebooks.items():
        codebook = gop_data['unified_codebook']
        counts = _np.zeros(len(codebook), dtype=int)
        
        # GOP èŒƒå›´ï¼šèµ·å§‹å¸§ä¸‹ä¸€ä¸ªåˆ°ä¸‹ä¸€ä¸ª I å¸§
        gop_end = min(gop_start + args.i_frame_interval, len(frames))
        
        # ç»Ÿè®¡æ¯ä¸ªç æœ¬é¡¹çš„ä½¿ç”¨é¢‘æ¬¡
        for fid in range(gop_start + 1, gop_end):
            cur = frames[fid]
            prev = frames[fid - 1]
            # è¯†åˆ«æ›´æ–°çš„å¤§å—
            updated = identify_updated_big_blocks(cur, prev, args.diff_threshold)
            # å–å‡ºè¯¥å¸§çš„ block_types
            bt_map = None
            for fno, bt in gop_data['block_types_list']:
                if fno == fid:
                    bt_map = bt; break
            # ç´¯åŠ æ¯ä¸ªçº¹ç†å­å—çš„ç´¢å¼•ä½¿ç”¨æ¬¡æ•°
            for by, bx in updated:
                is_color = bt_map and bt_map.get((by, bx), ('detail',))[0] == 'color'
                if not is_color:
                    for sy in (0,1):
                        for sx in (0,1):
                            y, x = by*2+sy, bx*2+sx
                            if y < cur.shape[0] and x < cur.shape[1]:
                                b = cur[y, x]
                                idx = quantize_blocks_unified(b.reshape(1, -1), codebook)[0]
                                counts[idx] += 1
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä½¿ç”¨é¢‘æ¬¡å·®å¼‚
        max_count = counts.max()
        min_count = counts.min()
        total_usage = counts.sum()
        
        if max_count > min_count and total_usage > 0:
            print(f"  GOP {gop_start}: æœ€å¤§ä½¿ç”¨é¢‘æ¬¡ {max_count}, æœ€å°ä½¿ç”¨é¢‘æ¬¡ {min_count}, æ€»ä½¿ç”¨æ¬¡æ•° {total_usage}")
            
            # æ˜¾ç¤ºæ’åºå‰çš„å‰10ä¸ªæœ€å¸¸ç”¨é¡¹
            top_indices_before = _np.argsort(-counts)[:10]
            # print(f"    æ’åºå‰å‰10ä¸ªæœ€å¸¸ç”¨é¡¹: {top_indices_before.tolist()}")
            # print(f"    å¯¹åº”ä½¿ç”¨é¢‘æ¬¡: {counts[top_indices_before].tolist()}")
            
            # æ ¹æ® counts é™åºæ’åºï¼Œstable ä¿æŒç›¸åŒé¢‘æ¬¡é¡¹åŸåº
            order = _np.argsort(-counts, kind='stable')
            gop_data['unified_codebook'] = codebook[order]
            
            # åˆ›å»ºç´¢å¼•æ˜ å°„è¡¨ï¼ˆæ—§ç´¢å¼• -> æ–°ç´¢å¼•ï¼‰
            index_mapping = _np.zeros(len(codebook), dtype=int)
            for new_idx, old_idx in enumerate(order):
                index_mapping[old_idx] = new_idx
            
            # æ˜¾ç¤ºæ’åºåçš„å‰10ä¸ªé¡¹ï¼ˆåº”è¯¥å¯¹åº”åŸæ¥çš„æœ€å¸¸ç”¨é¡¹ï¼‰
            # print(f"    æ’åºåå‰10ä¸ªé¡¹å¯¹åº”åŸç´¢å¼•: {order[:10].tolist()}")
            
            # # éªŒè¯æ’åºæ•ˆæœï¼šæ£€æŸ¥æ’åºåå‰å‡ ä¸ªç´¢å¼•çš„ä½¿ç”¨æƒ…å†µ
            # print(f"    æ’åºåå‰15ä¸ªç´¢å¼•çš„ä½¿ç”¨é¢‘æ¬¡: {counts[order[:15]].tolist()}")
            # print(f"    æ’åºåå‰15ä¸ªç´¢å¼•çš„æ®µåˆ†å¸ƒ: {[i//15 for i in range(15)]}")
            
            # æ›´æ–° block_types ä¸­çš„ç´¢å¼•
            for fid, bt in gop_data['block_types_list']:
                if bt is not None:
                    for (big_by, big_bx), (block_type, block_indices) in bt.items():
                        if block_type == 'detail':
                            # æ›´æ–°çº¹ç†å—çš„ç´¢å¼•
                            new_indices = []
                            for old_idx in block_indices:
                                if old_idx < len(index_mapping):
                                    new_indices.append(index_mapping[old_idx])
                                else:
                                    new_indices.append(old_idx)
                            bt[(big_by, big_bx)] = (block_type, new_indices)
        else:
            # print(f"  GOP {gop_start}: æ‰€æœ‰ç æœ¬é¡¹ä½¿ç”¨é¢‘æ¬¡ç›¸åŒæˆ–æ€»ä½¿ç”¨æ¬¡æ•°ä¸º0ï¼Œè·³è¿‡æ’åº")
    
    # ç¼–ç æ‰€æœ‰å¸§
    print("æ­£åœ¨ç¼–ç å¸§...")
    encoded_frames = []
    frame_offsets = []
    current_offset = 0
    prev_frame = None
    
    for frame_idx, current_frame in enumerate(frames):
        frame_offsets.append(current_offset)
        
        # æ‰¾åˆ°å½“å‰GOP
        gop_start = (frame_idx // args.i_frame_interval) * args.i_frame_interval
        gop_data = gop_codebooks[gop_start]
        
        unified_codebook = gop_data['unified_codebook']
        
        # æ‰¾åˆ°å½“å‰å¸§çš„block_typesï¼Œå¤„ç†ç¼ºå¤±çš„æƒ…å†µ
        block_types = None
        for fid, bt in gop_data['block_types_list']:
            if fid == frame_idx:
                block_types = bt
                break
        
        # å¦‚æœblock_typesä»ç„¶ä¸ºNoneï¼Œç”Ÿæˆé»˜è®¤çš„block_types
        if block_types is None:
            print(f"  âš ï¸ å¸§ {frame_idx} ç¼ºå°‘block_typesï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»")
            # ä¸´æ—¶ç”Ÿæˆblock_types
            _, block_types = classify_4x4_blocks_unified(current_frame, args.variance_threshold)
        
        force_i_frame = (frame_idx % args.i_frame_interval == 0) or frame_idx == 0
        
        if force_i_frame or prev_frame is None:
            frame_data = encode_i_frame_unified(
                current_frame, unified_codebook, block_types
            )
            is_i_frame = True
            
            # è®¡ç®—ç æœ¬å’Œç´¢å¼•å¤§å°
            codebook_size = args.codebook_size * BYTES_PER_BLOCK
            index_size = len(frame_data) - 1 - codebook_size
            
            encoding_stats.add_i_frame(
                len(frame_data), 
                is_forced=force_i_frame,
                codebook_size=codebook_size,
                index_size=max(0, index_size)
            )
        else:
            frame_data, is_i_frame, used_zones, color_updates, detail_updates, small_updates, medium_updates, full_updates, small_bytes, medium_bytes, full_bytes, small_segments, medium_segments, small_blocks_per_update, medium_blocks_per_update, full_blocks_per_update = encode_p_frame_unified(
                current_frame, prev_frame,
                unified_codebook, block_types,
                args.diff_threshold, args.force_i_threshold, args.enabled_segments_bitmap,
                args.enabled_medium_segments_bitmap
            )
            
            if is_i_frame:
                codebook_size = args.codebook_size * BYTES_PER_BLOCK
                index_size = len(frame_data) - 1 - codebook_size
                
                encoding_stats.add_i_frame(
                    len(frame_data), 
                    is_forced=False,
                    codebook_size=codebook_size,
                    index_size=max(0, index_size)
                )
            else:
                total_updates = color_updates + detail_updates
                
                encoding_stats.add_p_frame(
                    len(frame_data), total_updates, used_zones,
                    color_updates, detail_updates,
                    small_updates, medium_updates, full_updates,
                    small_bytes, medium_bytes, full_bytes,
                    small_segments, medium_segments,
                    small_blocks_per_update, medium_blocks_per_update, full_blocks_per_update
                )
        
        encoded_frames.append(frame_data)
        current_offset += len(frame_data)
        
        prev_frame = current_frame.copy() if current_frame.size > 0 else None
        
        if frame_idx % 30 == 0 or frame_idx == len(frames) - 1:
            print(f"  å·²ç¼–ç  {frame_idx + 1}/{len(frames)} å¸§")
    
    all_data = b''.join(encoded_frames)
    
    write_header(pathlib.Path(args.out).with_suffix(".h"), len(frames), len(all_data), 
                args.codebook_size, actual_output_fps)
    write_source(pathlib.Path(args.out).with_suffix(".c"), all_data, frame_offsets)
    
    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    encoding_stats.print_summary(len(frames), len(all_data))

def write_header(path_h: pathlib.Path, frame_cnt: int, total_bytes: int, codebook_size: int, output_fps: float):
    guard = "VIDEO_DATA_H"
    
    with path_h.open("w", encoding="utf-8") as f:
        f.write(textwrap.dedent(f"""\
            #ifndef {guard}
            #define {guard}

            #define VIDEO_FRAME_COUNT   {frame_cnt}
            #define VIDEO_WIDTH         {WIDTH}
            #define VIDEO_HEIGHT        {HEIGHT}
            #define VIDEO_TOTAL_BYTES   {total_bytes}
            #define VIDEO_FPS           {int(round(output_fps*10000))}
            #define UNIFIED_CODEBOOK_SIZE {codebook_size}
            #define EFFECTIVE_UNIFIED_CODEBOOK_SIZE {EFFECTIVE_UNIFIED_CODEBOOK_SIZE}
            
            // å¸§ç±»å‹å®šä¹‰
            #define FRAME_TYPE_I        0x00
            #define FRAME_TYPE_P        0x01
            
            // ç‰¹æ®Šæ ‡è®°
            #define COLOR_BLOCK_MARKER  0xFF
            
            // å—å‚æ•°
            #define BLOCK_WIDTH         2
            #define BLOCK_HEIGHT        2
            #define BYTES_PER_BLOCK     7
            
            extern const unsigned char video_data[VIDEO_TOTAL_BYTES];
            extern const unsigned int frame_offsets[VIDEO_FRAME_COUNT];

            #endif // {guard}
            """))

encoding_stats = EncodingStats()
def write_source(path_c: pathlib.Path, data: bytes, frame_offsets: list):
    with path_c.open("w", encoding="utf-8") as f:
        f.write('#include "video_data.h"\n\n')
        
        f.write("const unsigned int frame_offsets[] = {\n")
        for i in range(0, len(frame_offsets), 8):
            chunk = ', '.join(f"{offset}" for offset in frame_offsets[i:i+8])
            f.write("    " + chunk + ",\n")
        f.write("};\n\n")
        
        f.write("const unsigned char video_data[] = {\n")
        per_line = 16
        for i in range(0, len(data), per_line):
            chunk = ', '.join(f"0x{v:02X}" for v in data[i:i+per_line])
            f.write("    " + chunk + ",\n")
        f.write("};\n")

if __name__ == "__main__":
    main()
