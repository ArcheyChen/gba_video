#!/usr/bin/env python3

import argparse, cv2, numpy as np, pathlib, textwrap
import struct
import concurrent.futures
from sklearn.cluster import MiniBatchKMeans
from scipy.spatial.distance import cdist
from collections import defaultdict
import statistics
from numba import jit, njit, types
from numba.typed import List

from dither_opt import apply_dither_optimized

WIDTH, HEIGHT = 240, 160
DEFAULT_STRIP_COUNT = 4
DEFAULT_UNIFIED_CODEBOOK_SIZE = 256   # ç»Ÿä¸€ç æœ¬å¤§å°
EFFECTIVE_UNIFIED_CODEBOOK_SIZE = 255  # æœ‰æ•ˆç æœ¬å¤§å°ï¼ˆ0xFFä¿ç•™ï¼‰
DEFAULT_4X4_CODEBOOK_SIZE = 128  # 4x4å—ç è¡¨å¤§å°

# æ ‡è®°å¸¸é‡
BLOCK_4X4_MARKER = 0xFF

Y_COEFF  = np.array([0.28571429,  0.57142857,  0.14285714])
CB_COEFF = np.array([-0.14285714, -0.28571429,  0.42857143])
CR_COEFF = np.array([ 0.35714286, -0.28571429, -0.07142857])
BLOCK_W, BLOCK_H = 2, 2
BYTES_PER_2X2_BLOCK  = 7  # 4Y + d_r + d_g + d_b
BYTES_PER_4X4_BLOCK = 28  # 16Y + 4*(d_r + d_g + d_b)

# æ–°å¢å¸¸é‡ - æ”¹ä¸º8x8å•ä½
SUPER_BLOCK_SIZE = 8  # 8x8è¶…çº§å—
ZONE_HEIGHT_PIXELS = 16  # æ¯ä¸ªåŒºåŸŸçš„åƒç´ é«˜åº¦
ZONE_HEIGHT_SUPER_BLOCKS = ZONE_HEIGHT_PIXELS // SUPER_BLOCK_SIZE  # æ¯ä¸ªåŒºåŸŸçš„8x8è¶…çº§å—è¡Œæ•° (16åƒç´  = 2è¡Œ8x8è¶…çº§å—)

# å¸§ç±»å‹æ ‡è¯†
FRAME_TYPE_I = 0x00  # Iå¸§ï¼ˆå…³é”®å¸§ï¼‰
FRAME_TYPE_P = 0x01  # På¸§ï¼ˆå·®åˆ†å¸§ï¼‰

def calculate_strip_heights(height: int, strip_count: int) -> list:
    """è®¡ç®—æ¯ä¸ªæ¡å¸¦çš„é«˜åº¦ï¼Œç¡®ä¿æ¯ä¸ªæ¡å¸¦é«˜åº¦éƒ½æ˜¯4çš„å€æ•°"""
    if height % 4 != 0:
        raise ValueError(f"è§†é¢‘é«˜åº¦ {height} å¿…é¡»æ˜¯4çš„å€æ•°")
    
    base_height = (height // strip_count // 4) * 4
    remaining_height = height - (base_height * strip_count)
    
    strip_heights = []
    for i in range(strip_count):
        current_height = base_height
        if remaining_height >= 4:
            current_height += 4
            remaining_height -= 4
        strip_heights.append(current_height)
    
    if sum(strip_heights) != height:
        raise ValueError(f"æ¡å¸¦é«˜åº¦åˆ†é…é”™è¯¯: {strip_heights} æ€»å’Œ {sum(strip_heights)} != {height}")
    
    for i, h in enumerate(strip_heights):
        if h % 4 != 0:
            raise ValueError(f"æ¡å¸¦ {i} é«˜åº¦ {h} ä¸æ˜¯4çš„å€æ•°")
    
    return strip_heights

@njit
def clip_value(value, min_val, max_val):
    """Numbaå…¼å®¹çš„clipå‡½æ•°"""
    if value < min_val:
        return min_val
    elif value > max_val:
        return max_val
    else:
        return value

@njit
def pack_yuv420_strip_numba(bgr_strip, strip_height, width):
    """NumbaåŠ é€Ÿçš„YUV420è½¬æ¢"""
    blocks_h = strip_height // BLOCK_H
    blocks_w = width // BLOCK_W
    
    block_array = np.zeros((blocks_h, blocks_w, BYTES_PER_2X2_BLOCK), dtype=np.uint8)
    
    for by in range(blocks_h):
        for bx in range(blocks_w):
            # æå–2x2å—
            y_start = by * BLOCK_H
            x_start = bx * BLOCK_W
            
            # BGR to YUV conversion for 2x2 block
            cb_sum = 0.0
            cr_sum = 0.0
            y_values = np.zeros(4, dtype=np.uint8)
            
            idx = 0
            for dy in range(BLOCK_H):
                for dx in range(BLOCK_W):
                    if y_start + dy < strip_height and x_start + dx < width:
                        b = float(bgr_strip[y_start + dy, x_start + dx, 0])
                        g = float(bgr_strip[y_start + dy, x_start + dx, 1])  
                        r = float(bgr_strip[y_start + dy, x_start + dx, 2])
                        
                        y = r * 0.28571429 + g * 0.57142857 + b * 0.14285714
                        cb = r * (-0.14285714) + g * (-0.28571429) + b * 0.42857143
                        cr = r * 0.35714286 + g * (-0.28571429) + b * (-0.07142857)
                        
                        y_values[idx] = np.uint8(clip_value(y / 2.0, 0.0, 255.0))
                        cb_sum += cb
                        cr_sum += cr
                        idx += 1
            
            # Store Y values
            block_array[by, bx, 0:4] = y_values
            
            # Compute and store chroma
            cb_mean = cb_sum / 4.0
            cr_mean = cr_sum / 4.0
            
            d_r = clip_value(cr_mean, -128.0, 127.0)
            d_g = clip_value((-(cb_mean/2.0) - cr_mean) / 2.0, -128.0, 127.0)  
            d_b = clip_value(cb_mean, -128.0, 127.0)
            
            # å°†æœ‰ç¬¦å·å€¼è½¬æ¢ä¸ºæ— ç¬¦å·å­—èŠ‚å­˜å‚¨
            block_array[by, bx, 4] = np.uint8(np.int8(d_r).view(np.uint8))
            block_array[by, bx, 5] = np.uint8(np.int8(d_g).view(np.uint8))
            block_array[by, bx, 6] = np.uint8(np.int8(d_b).view(np.uint8))
    
    return block_array

def pack_yuv420_strip(frame_bgr: np.ndarray, strip_y: int, strip_height: int) -> np.ndarray:
    """ä½¿ç”¨NumbaåŠ é€Ÿçš„YUVè½¬æ¢åŒ…è£…å‡½æ•°"""
    strip_bgr = frame_bgr[strip_y:strip_y + strip_height, :, :]
    return pack_yuv420_strip_numba(strip_bgr, strip_height, WIDTH)

def generate_4x4_codebook(blocks_4x4: list, codebook_size: int = DEFAULT_4X4_CODEBOOK_SIZE, 
                         max_iter: int = 100) -> np.ndarray:
    """ç”Ÿæˆ4x4å—ç è¡¨"""
    if len(blocks_4x4) == 0:
        return np.zeros((codebook_size, BYTES_PER_4X4_BLOCK), dtype=np.uint8)
    
    blocks_4x4_array = np.array(blocks_4x4)
    if len(blocks_4x4_array) <= codebook_size:
        # æ•°æ®é‡å°äºç è¡¨å¤§å°
        codebook = np.zeros((codebook_size, BYTES_PER_4X4_BLOCK), dtype=np.uint8)
        codebook[:len(blocks_4x4_array)] = blocks_4x4_array
        if len(blocks_4x4_array) > 0:
            for i in range(len(blocks_4x4_array), codebook_size):
                codebook[i] = blocks_4x4_array[-1]
        return codebook
    
    # ä½¿ç”¨K-Meansèšç±»
    blocks_4x4_for_clustering = convert_4x4_blocks_for_clustering(blocks_4x4_array)
    kmeans = MiniBatchKMeans(
        n_clusters=codebook_size,
        random_state=42,
        batch_size=min(1000, len(blocks_4x4_array)),
        max_iter=max_iter,
        n_init=3
    )
    kmeans.fit(blocks_4x4_for_clustering)
    codebook = convert_4x4_codebook_from_clustering(kmeans.cluster_centers_)
    
    return codebook

def convert_4x4_blocks_for_clustering(blocks_4x4: np.ndarray) -> np.ndarray:
    """å°†4x4å—è½¬æ¢ä¸ºèšç±»æ ¼å¼"""
    if len(blocks_4x4) == 0:
        return blocks_4x4.astype(np.float32)
    
    if blocks_4x4.ndim > 2:
        blocks_4x4 = blocks_4x4.reshape(-1, BYTES_PER_4X4_BLOCK)
    
    blocks_4x4_float = blocks_4x4.astype(np.float32)
    
    # è‰²åº¦åˆ†é‡éœ€è¦è½¬æ¢ä¸ºæœ‰ç¬¦å·æ•°
    for i in range(16, BYTES_PER_4X4_BLOCK):
        blocks_4x4_float[:, i] = blocks_4x4[:, i].view(np.int8).astype(np.float32)
    
    return blocks_4x4_float

def convert_4x4_codebook_from_clustering(codebook_float: np.ndarray) -> np.ndarray:
    """å°†èšç±»ç»“æœè½¬æ¢å›4x4å—æ ¼å¼"""
    codebook = np.zeros_like(codebook_float, dtype=np.uint8)
    
    # Yåˆ†é‡
    codebook[:, 0:16] = np.clip(codebook_float[:, 0:16].round(), 0, 255).astype(np.uint8)
    
    # è‰²åº¦åˆ†é‡
    for i in range(16, BYTES_PER_4X4_BLOCK):
        clipped_values = np.clip(codebook_float[:, i].round(), -128, 127).astype(np.int8)
        codebook[:, i] = clipped_values.view(np.uint8)
    
    return codebook

def quantize_4x4_blocks(blocks_4x4: list, codebook_4x4: np.ndarray) -> tuple:
    """é‡åŒ–4x4å—ï¼Œè¿”å›ç´¢å¼•å’Œé‡å»ºçš„å—"""
    if len(blocks_4x4) == 0:
        return np.array([], dtype=np.uint8), []
    
    blocks_4x4_array = np.array(blocks_4x4)
    blocks_4x4_for_clustering = convert_4x4_blocks_for_clustering(blocks_4x4_array)
    codebook_4x4_for_clustering = convert_4x4_blocks_for_clustering(codebook_4x4)
    
    # è®¡ç®—è·ç¦»å’Œæ‰¾åˆ°æœ€è¿‘çš„ç å­—
    distances = cdist(blocks_4x4_for_clustering, codebook_4x4_for_clustering, metric='euclidean')
    indices = np.argmin(distances, axis=1).astype(np.uint8)
    
    # é‡å»ºå—
    reconstructed_4x4_blocks = [codebook_4x4[idx] for idx in indices]
    
    return indices, reconstructed_4x4_blocks

def classify_8x8_super_blocks_with_4x4_codebook(blocks: np.ndarray, codebook_4x4: np.ndarray,
                                              variance_threshold: float = 5.0, 
                                              distortion_threshold: float = 10.0) -> tuple:
    """ä½¿ç”¨4x4å—ç è¡¨å¯¹8x8è¶…çº§å—è¿›è¡Œåˆ†ç±»"""
    blocks_h, blocks_w = blocks.shape[:2]
    super_blocks_h = blocks_h // 4  # 8x8è¶…çº§å— = 4ä¸ª2x2å—çš„è¡Œæ•°
    super_blocks_w = blocks_w // 4  # 8x8è¶…çº§å— = 4ä¸ª2x2å—çš„åˆ—æ•°
    
    block_4x4_indices = {}  # ä½¿ç”¨4x4å—ç è¡¨çš„è¶…çº§å—
    blocks_2x2 = []         # éœ€è¦ç”¨2x2å—ç è¡¨çš„å—
    block_types = {}        # è®°å½•æ¯ä¸ª8x8è¶…çº§å—çš„ç±»å‹
    
    for super_by in range(super_blocks_h):
        for super_bx in range(super_blocks_w):
            # æ”¶é›†8x8è¶…çº§å—å†…çš„16ä¸ª2x2å— - æŒ‰è¡Œä¼˜å…ˆé¡ºåº
            blocks_8x8 = []
            for sub_by in range(4):  # 4è¡Œ2x2å—
                for sub_bx in range(4):  # 4åˆ—2x2å—
                    by = super_by * 4 + sub_by
                    bx = super_bx * 4 + sub_bx
                    if by < blocks_h and bx < blocks_w:
                        blocks_8x8.append(blocks[by, bx])
                    else:
                        blocks_8x8.append(np.zeros(BYTES_PER_2X2_BLOCK, dtype=np.uint8))
            
            # å°†16ä¸ª2x2å—é‡ç»„ä¸º4ä¸ª4x4å—
            blocks_4x4_in_super = []
            for quad_idx in range(4):  # 4ä¸ª4x4å—
                quad_by = quad_idx // 2
                quad_bx = quad_idx % 2
                blocks_2x2_in_4x4 = []
                for sub_by in range(2):
                    for sub_bx in range(2):
                        block_idx = (quad_by * 2 + sub_by) * 4 + (quad_bx * 2 + sub_bx)
                        blocks_2x2_in_4x4.append(blocks_8x8[block_idx])
                block_4x4 = pack_4x4_block_from_2x2_blocks(blocks_2x2_in_4x4)
                blocks_4x4_in_super.append(block_4x4)
            
            # å°è¯•ç”¨4x4å—ç è¡¨
            indices, reconstructed = quantize_4x4_blocks(blocks_4x4_in_super, codebook_4x4)
            
            if len(reconstructed) > 0:
                # è®¡ç®—å¤±çœŸ
                reconstructed_2x2_blocks = []
                for block_4x4 in reconstructed:
                    reconstructed_2x2_blocks.extend(unpack_4x4_block_to_2x2_blocks(block_4x4))
                distortion = calculate_distortion(blocks_8x8, reconstructed_2x2_blocks)
                
                if distortion <= distortion_threshold:
                    # å¤±çœŸå¯æ¥å—ï¼Œä½¿ç”¨4x4å—ç è¡¨
                    block_4x4_indices[(super_by, super_bx)] = indices
                    block_types[(super_by, super_bx)] = '4x4_blocks'
                else:
                    # å¤±çœŸå¤ªå¤§ï¼Œä½¿ç”¨2x2å—ç è¡¨
                    blocks_2x2.extend(blocks_8x8)
                    block_types[(super_by, super_bx)] = '2x2_blocks'
            else:
                # é‡åŒ–å¤±è´¥ï¼Œä½¿ç”¨2x2å—ç è¡¨
                blocks_2x2.extend(blocks_8x8)
                block_types[(super_by, super_bx)] = '2x2_blocks'
    
    return block_4x4_indices, blocks_2x2, block_types

def encode_strip_i_frame_with_4x4_blocks(blocks: np.ndarray, codebook_4x4: np.ndarray,
                                        codebook_2x2: np.ndarray, block_types: dict,
                                        block_4x4_indices: dict) -> bytes:
    """ç¼–ç Iå¸§æ¡å¸¦"""
    data = bytearray()
    data.append(FRAME_TYPE_I)
    
    if blocks.size > 0:
        blocks_h, blocks_w = blocks.shape[:2]
        super_blocks_h = blocks_h // 4
        super_blocks_w = blocks_w // 4
        
        # å­˜å‚¨4x4å—ç è¡¨
        data.extend(codebook_4x4.flatten().tobytes())
        
        # å­˜å‚¨2x2å—ç è¡¨
        data.extend(codebook_2x2.flatten().tobytes())
        
        # æŒ‰8x8è¶…çº§å—çš„é¡ºåºç¼–ç 
        for super_by in range(super_blocks_h):
            for super_bx in range(super_blocks_w):
                if (super_by, super_bx) in block_types:
                    block_type = block_types[(super_by, super_bx)]
                    
                    if block_type == '4x4_blocks':
                        # 4x4å—ï¼š0xFF + 4ä¸ª4x4å—ç è¡¨ç´¢å¼•
                        data.append(BLOCK_4X4_MARKER)
                        indices_4x4 = block_4x4_indices[(super_by, super_bx)]
                        for idx in indices_4x4:
                            data.append(idx)
                        
                    else:  # 2x2_blocks
                        # çº¹ç†å—ï¼š16ä¸ª2x2å—ç è¡¨ç´¢å¼•ï¼ŒæŒ‰è¡Œä¼˜å…ˆé¡ºåº
                        for sub_by in range(4):
                            for sub_bx in range(4):
                                by = super_by * 4 + sub_by
                                bx = super_bx * 4 + sub_bx
                                if by < blocks_h and bx < blocks_w:
                                    block = blocks[by, bx]
                                    idx_2x2 = quantize_blocks_unified(block.reshape(1, -1), codebook_2x2)[0]
                                    data.append(idx_2x2)
                                else:
                                    data.append(0)
    
    return bytes(data)

def generate_gop_codebooks_with_4x4_blocks(frames: list, strip_count: int, i_frame_interval: int,
                                         variance_threshold: float, diff_threshold: float,
                                         distortion_threshold: float = 10.0,
                                         codebook_4x4_size: int = DEFAULT_4X4_CODEBOOK_SIZE,
                                         codebook_2x2_size: int = EFFECTIVE_UNIFIED_CODEBOOK_SIZE,
                                         kmeans_max_iter: int = 100, i_frame_weight: int = 3) -> dict:
    """ä¸ºæ¯ä¸ªGOPç”Ÿæˆ4x4å—ç è¡¨å’Œ2x2å—ç è¡¨"""
    print("æ­£åœ¨ä¸ºæ¯ä¸ªGOPç”Ÿæˆ4x4å—ç è¡¨å’Œ2x2å—ç è¡¨...")
    
    gop_codebooks = {}
    
    i_frame_positions = []
    for frame_idx in range(len(frames)):
        if frame_idx % i_frame_interval == 0:
            i_frame_positions.append(frame_idx)
    
    for gop_idx, gop_start in enumerate(i_frame_positions):
        if gop_idx + 1 < len(i_frame_positions):
            gop_end = i_frame_positions[gop_idx + 1]
        else:
            gop_end = len(frames)
        
        print(f"  å¤„ç†GOP {gop_idx}: å¸§ {gop_start} åˆ° {gop_end-1}")
        
        gop_codebooks[gop_start] = []
        
        for strip_idx in range(strip_count):
            all_4x4_blocks = []
            all_2x2_blocks = []
            block_types_list = []
            
            # å¤„ç†GOPä¸­çš„æ¯ä¸€å¸§
            prev_strip_blocks = None
            
            for frame_idx in range(gop_start, gop_end):
                strip_blocks = frames[frame_idx][strip_idx]
                if strip_blocks.size == 0:
                    continue
                
                # ç¡®å®šéœ€è¦å¤„ç†çš„8x8è¶…çº§å—
                is_i_frame = (frame_idx == gop_start)
                
                if is_i_frame:
                    blocks_h, blocks_w = strip_blocks.shape[:2]
                    super_blocks_h = blocks_h // 4
                    super_blocks_w = blocks_w // 4
                    updated_super_blocks = {(super_by, super_bx) for super_by in range(super_blocks_h) for super_bx in range(super_blocks_w)}
                else:
                    updated_super_blocks = identify_updated_8x8_super_blocks(strip_blocks, prev_strip_blocks, diff_threshold)
                
                # ä»æœ‰æ•ˆ8x8è¶…çº§å—ä¸­æå–æ•°æ®ç”¨äºè®­ç»ƒç è¡¨
                for super_by, super_bx in updated_super_blocks:
                    blocks_8x8 = []
                    for sub_by in range(4):
                        for sub_bx in range(4):
                            by = super_by * 4 + sub_by
                            bx = super_bx * 4 + sub_bx
                            if by < strip_blocks.shape[0] and bx < strip_blocks.shape[1]:
                                blocks_8x8.append(strip_blocks[by, bx])
                            else:
                                blocks_8x8.append(np.zeros(BYTES_PER_2X2_BLOCK, dtype=np.uint8))
                    
                    # å°†16ä¸ª2x2å—é‡ç»„ä¸º4ä¸ª4x4å—
                    blocks_4x4_in_super = []
                    for quad_idx in range(4):
                        quad_by = quad_idx // 2
                        quad_bx = quad_idx % 2
                        blocks_2x2_in_4x4 = []
                        for sub_by in range(2):
                            for sub_bx in range(2):
                                block_idx = (quad_by * 2 + sub_by) * 4 + (quad_bx * 2 + sub_bx)
                                blocks_2x2_in_4x4.append(blocks_8x8[block_idx])
                        block_4x4 = pack_4x4_block_from_2x2_blocks(blocks_2x2_in_4x4)
                        blocks_4x4_in_super.append(block_4x4)
                    
                    # æ·»åŠ åˆ°è®­ç»ƒæ•°æ®
                    if is_i_frame:
                        all_4x4_blocks.extend(blocks_4x4_in_super * i_frame_weight)
                        all_2x2_blocks.extend(blocks_8x8 * i_frame_weight)
                    else:
                        all_4x4_blocks.extend(blocks_4x4_in_super)
                        all_2x2_blocks.extend(blocks_8x8)
                
                prev_strip_blocks = strip_blocks.copy()
            
            # ç”Ÿæˆç è¡¨
            codebook_4x4 = generate_4x4_codebook(all_4x4_blocks, codebook_4x4_size, kmeans_max_iter)
            codebook_2x2 = generate_unified_codebook_simplified(
                all_2x2_blocks, codebook_2x2_size, kmeans_max_iter)
            
            # ä¸ºæ¯ä¸€å¸§ç”Ÿæˆåˆ†ç±»ä¿¡æ¯
            for frame_idx in range(gop_start, gop_end):
                strip_blocks = frames[frame_idx][strip_idx]
                if strip_blocks.size == 0:
                    continue
                
                block_4x4_indices, _, block_types = classify_8x8_super_blocks_with_4x4_codebook(
                    strip_blocks, codebook_4x4, variance_threshold, distortion_threshold)
                block_types_list.append((frame_idx, block_types, block_4x4_indices))
            
            gop_codebooks[gop_start].append({
                'codebook_4x4': codebook_4x4,
                'codebook_2x2': codebook_2x2,
                'block_types_list': block_types_list,
                'distortion_threshold': distortion_threshold
            })
            
            print(f"    æ¡å¸¦{strip_idx}: 4x4å—{len(all_4x4_blocks)}ä¸ª, 2x2å—{len(all_2x2_blocks)}ä¸ª")
    
    return gop_codebooks

def pack_4x4_block_from_2x2_blocks(blocks_2x2: list) -> np.ndarray:
    """å°†4ä¸ª2x2å—ç»„åˆæˆä¸€ä¸ª4x4å—"""
    block_4x4 = np.zeros(BYTES_PER_4X4_BLOCK, dtype=np.uint8)
    
    # ç›´æ¥æŒ‰è¡Œä¼˜å…ˆé¡ºåºå­˜å‚¨4ä¸ªYUV_Struct
    # blocks_2x2çš„é¡ºåºåº”è¯¥æ˜¯ï¼š[å·¦ä¸Š, å³ä¸Š, å·¦ä¸‹, å³ä¸‹]
    for i, block in enumerate(blocks_2x2):
        if len(block) >= BYTES_PER_2X2_BLOCK:
            start_offset = i * BYTES_PER_2X2_BLOCK
            block_4x4[start_offset:start_offset + BYTES_PER_2X2_BLOCK] = block[:BYTES_PER_2X2_BLOCK]
    
    return block_4x4

def unpack_4x4_block_to_2x2_blocks(block_4x4: np.ndarray) -> list:
    """å°†4x4å—æ‹†åˆ†æˆ4ä¸ª2x2å—"""
    blocks_2x2 = []
    
    for i in range(4):
        start_offset = i * BYTES_PER_2X2_BLOCK
        block = block_4x4[start_offset:start_offset + BYTES_PER_2X2_BLOCK].copy()
        blocks_2x2.append(block)
    
    return blocks_2x2

def identify_updated_8x8_super_blocks(current_blocks: np.ndarray, prev_blocks: np.ndarray,
                                    diff_threshold: float) -> set:
    """è¯†åˆ«éœ€è¦æ›´æ–°çš„8x8è¶…çº§å—ä½ç½®"""
    if prev_blocks is None or current_blocks.shape != prev_blocks.shape:
        # å¦‚æœæ²¡æœ‰å‰ä¸€å¸§ï¼Œæ‰€æœ‰è¶…çº§å—éƒ½éœ€è¦æ›´æ–°
        blocks_h, blocks_w = current_blocks.shape[:2]
        super_blocks_h = blocks_h // 4
        super_blocks_w = blocks_w // 4
        return {(super_by, super_bx) for super_by in range(super_blocks_h) for super_bx in range(super_blocks_w)}
    
    blocks_h, blocks_w = current_blocks.shape[:2]
    
    # ä½¿ç”¨NumbaåŠ é€Ÿçš„å—å·®å¼‚è®¡ç®—
    current_flat = current_blocks.reshape(-1, BYTES_PER_2X2_BLOCK)
    prev_flat = prev_blocks.reshape(-1, BYTES_PER_2X2_BLOCK)
    block_diffs = compute_block_differences_numba(current_flat, prev_flat, blocks_h, blocks_w)
    
    # ä½¿ç”¨NumbaåŠ é€Ÿçš„æ›´æ–°å—è¯†åˆ«
    updated_list = identify_updated_8x8_super_blocks_numba(block_diffs, diff_threshold, blocks_h, blocks_w)
    
    return set(updated_list)

@njit
def identify_updated_8x8_super_blocks_numba(block_diffs, diff_threshold, blocks_h, blocks_w):
    """NumbaåŠ é€Ÿçš„8x8è¶…çº§å—æ›´æ–°è¯†åˆ«"""
    super_blocks_h = blocks_h // 4
    super_blocks_w = blocks_w // 4
    updated_positions = []
    
    for super_by in range(super_blocks_h):
        for super_bx in range(super_blocks_w):
            needs_update = False
            
            # æ£€æŸ¥16ä¸ª2x2å­å—çš„ä½ç½®
            for sub_by in range(4):
                for sub_bx in range(4):
                    by = super_by * 4 + sub_by
                    bx = super_bx * 4 + sub_bx
                    
                    if by < blocks_h and bx < blocks_w:
                        if block_diffs[by, bx] > diff_threshold:
                            needs_update = True
                            break
                if needs_update:
                    break
            
            if needs_update:
                updated_positions.append((super_by, super_bx))
    
    return updated_positions

def encode_strip_p_frame_with_4x4_blocks(current_blocks: np.ndarray, prev_blocks: np.ndarray,
                                        codebook_4x4: np.ndarray, codebook_2x2: np.ndarray,
                                        block_types: dict, block_4x4_indices: dict,
                                        diff_threshold: float, force_i_threshold: float = 0.7,
                                        variance_threshold: float = 5.0, distortion_threshold: float = 10.0) -> tuple:
    """ç¼–ç På¸§æ¡å¸¦"""
    if prev_blocks is None or current_blocks.shape != prev_blocks.shape:
        i_frame_data = encode_strip_i_frame_with_4x4_blocks(
            current_blocks, codebook_4x4, codebook_2x2, block_types, block_4x4_indices)
        return i_frame_data, True, 0, 0, 0
    
    blocks_h, blocks_w = current_blocks.shape[:2]
    total_blocks = blocks_h * blocks_w
    
    if total_blocks == 0:
        return b'', True, 0, 0, 0
    
    # è¯†åˆ«éœ€è¦æ›´æ–°çš„8x8è¶…çº§å—
    updated_super_blocks = identify_updated_8x8_super_blocks(current_blocks, prev_blocks, diff_threshold)
    
    super_blocks_h = blocks_h // 4
    super_blocks_w = blocks_w // 4
    total_super_blocks = super_blocks_h * super_blocks_w
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦Iå¸§
    update_ratio = len(updated_super_blocks) / total_super_blocks if total_super_blocks > 0 else 0
    if update_ratio > force_i_threshold:
        i_frame_data = encode_strip_i_frame_with_4x4_blocks(
            current_blocks, codebook_4x4, codebook_2x2, block_types, block_4x4_indices)
        return i_frame_data, True, 0, 0, 0
    
    # è®¡ç®—åŒºåŸŸæ•°é‡ - åŸºäº8x8è¶…çº§å—
    zones_count = (super_blocks_h + ZONE_HEIGHT_SUPER_BLOCKS - 1) // ZONE_HEIGHT_SUPER_BLOCKS
    
    # æŒ‰åŒºåŸŸç»„ç»‡æ›´æ–°
    zone_4x4_updates = [[] for _ in range(zones_count)]
    zone_2x2_updates = [[] for _ in range(zones_count)]
    
    for super_by, super_bx in updated_super_blocks:
        # è®¡ç®—å±äºå“ªä¸ªåŒºåŸŸ
        zone_idx = min(super_by // ZONE_HEIGHT_SUPER_BLOCKS, zones_count - 1)
        zone_relative_by = super_by % ZONE_HEIGHT_SUPER_BLOCKS
        zone_relative_idx = zone_relative_by * super_blocks_w + super_bx
        
        if (super_by, super_bx) in block_types:
            block_type = block_types[(super_by, super_bx)]
            
            if block_type == '4x4_blocks':
                # 4x4å—æ›´æ–°
                indices_4x4 = block_4x4_indices[(super_by, super_bx)]
                zone_4x4_updates[zone_idx].append((zone_relative_idx, indices_4x4))
                
            else:  # 2x2_blocks
                # 2x2å—æ›´æ–°
                indices = []
                for sub_by in range(4):
                    for sub_bx in range(4):
                        by = super_by * 4 + sub_by
                        bx = super_bx * 4 + sub_bx
                        if by < blocks_h and bx < blocks_w:
                            block = current_blocks[by, bx]
                            idx_2x2 = quantize_blocks_unified(block.reshape(1, -1), codebook_2x2)[0]
                            indices.append(idx_2x2)
                        else:
                            indices.append(0)
                zone_2x2_updates[zone_idx].append((zone_relative_idx, indices))
    
    # ç¼–ç På¸§
    data = bytearray()
    data.append(FRAME_TYPE_P)
    
    # ç»Ÿè®¡ä½¿ç”¨çš„åŒºåŸŸæ•°é‡
    used_zones = 0
    total_4x4_updates = 0
    total_2x2_updates = 0
    
    # ç”ŸæˆåŒºåŸŸbitmap
    zone_bitmap = 0
    for zone_idx in range(zones_count):
        if zone_4x4_updates[zone_idx] or zone_2x2_updates[zone_idx]:
            zone_bitmap |= (1 << zone_idx)
            used_zones += 1
            total_4x4_updates += len(zone_4x4_updates[zone_idx])
            total_2x2_updates += len(zone_2x2_updates[zone_idx])
    
    data.extend(struct.pack('<H', zone_bitmap))
    
    # æŒ‰åŒºåŸŸç¼–ç æ›´æ–°ï¼ˆç°åœ¨åªæœ‰2ç§ç±»å‹ï¼‰
    for zone_idx in range(zones_count):
        if zone_bitmap & (1 << zone_idx):
            updates_2x2 = zone_2x2_updates[zone_idx]
            updates_4x4 = zone_4x4_updates[zone_idx]
            
            data.append(len(updates_2x2))
            data.append(len(updates_4x4))
            
            # å­˜å‚¨çº¹ç†å—æ›´æ–°
            for relative_idx, indices in updates_2x2:
                data.append(relative_idx)
                for idx in indices:
                    data.append(idx)
            
            # å­˜å‚¨4x4å—æ›´æ–°
            for relative_idx, indices_4x4 in updates_4x4:
                data.append(relative_idx)
                for idx in indices_4x4:
                    data.append(idx)
    
    total_updates = total_4x4_updates + total_2x2_updates
    return bytes(data), False, used_zones, total_4x4_updates, total_2x2_updates

def quantize_blocks_unified(blocks_data: np.ndarray, codebook: np.ndarray) -> np.ndarray:
    """ä½¿ç”¨ç»Ÿä¸€ç è¡¨å¯¹å—è¿›è¡Œé‡åŒ–ï¼ˆé¿å…äº§ç”Ÿ0xFEï¼‰"""
    if len(blocks_data) == 0:
        return np.array([], dtype=np.uint8)
    
    # åªä½¿ç”¨å‰è‹¥å¹²é¡¹è¿›è¡Œé‡åŒ–ï¼Œå› ä¸ºæœ€åå‡ é¡¹ç”¨äºç‰¹æ®Šæ ‡è®°
    effective_codebook = codebook[:EFFECTIVE_UNIFIED_CODEBOOK_SIZE]
    
    blocks_for_clustering = convert_blocks_for_clustering(blocks_data)
    codebook_for_clustering = convert_blocks_for_clustering(effective_codebook)
    
    # ä½¿ç”¨NumbaåŠ é€Ÿçš„è·ç¦»è®¡ç®—
    indices = quantize_blocks_distance_numba(blocks_for_clustering, codebook_for_clustering)
    
    return indices

@njit
def quantize_blocks_distance_numba(blocks_for_clustering, codebook_for_clustering):
    """NumbaåŠ é€Ÿçš„å—é‡åŒ–è·ç¦»è®¡ç®—"""
    n_blocks = blocks_for_clustering.shape[0]
    n_codebook = codebook_for_clustering.shape[0]
    indices = np.zeros(n_blocks, dtype=np.uint8)
    
    for i in range(n_blocks):
        min_dist = np.inf
        best_idx = 0
        
        for j in range(n_codebook):
            dist = 0.0
            # Yåˆ†é‡ï¼ˆå‰4ä¸ªå­—èŠ‚ï¼‰ä½¿ç”¨2å€æƒé‡ï¼Œè®¡ç®—SAD
            for k in range(4):
                diff = blocks_for_clustering[i, k] - codebook_for_clustering[j, k]
                dist += 2.0 * abs(diff)
            
            # è‰²åº¦åˆ†é‡ï¼ˆå3ä¸ªå­—èŠ‚ï¼‰ä½¿ç”¨1å€æƒé‡ï¼Œè®¡ç®—SAD
            # æ³¨æ„ï¼šè¿™é‡Œçš„æ•°æ®å·²ç»åœ¨convert_blocks_for_clusteringä¸­è½¬æ¢ä¸ºæœ‰ç¬¦å·æ•°
            for k in range(4, BYTES_PER_2X2_BLOCK):
                diff = blocks_for_clustering[i, k] - codebook_for_clustering[j, k]
                dist += abs(diff)
            
            if dist < min_dist:
                min_dist = dist
                best_idx = j
        
        indices[i] = best_idx
    
    return indices

def main():
    pa = argparse.ArgumentParser(description="Encode to GBA YUV9 with 4x4 block codebook")
    pa.add_argument("input")
    pa.add_argument("--duration", type=float, default=5.0)
    pa.add_argument("--full-duration", action="store_true")
    pa.add_argument("--fps", type=int, default=30)
    pa.add_argument("--out", default="video_data")
    pa.add_argument("--strip-count", type=int, default=DEFAULT_STRIP_COUNT)
    pa.add_argument("--i-frame-interval", type=int, default=60)
    pa.add_argument("--diff-threshold", type=float, default=2.0)
    pa.add_argument("--force-i-threshold", type=float, default=0.7)
    pa.add_argument("--variance-threshold", type=float, default=5.0)
    pa.add_argument("--distortion-threshold", type=float, default=10.0,
                   help="å¤±çœŸé˜ˆå€¼ï¼Œç”¨äºå†³å®šæ˜¯å¦ä½¿ç”¨4x4å—ç è¡¨ï¼ˆé»˜è®¤10.0ï¼‰")
    pa.add_argument("--codebook-4x4-size", type=int, default=DEFAULT_4X4_CODEBOOK_SIZE)
    pa.add_argument("--codebook-2x2-size", type=int, default=EFFECTIVE_UNIFIED_CODEBOOK_SIZE)
    pa.add_argument("--kmeans-max-iter", type=int, default=200)
    pa.add_argument("--threads", type=int, default=None)
    pa.add_argument("--i-frame-weight", type=int, default=3)
    pa.add_argument("--dither", action="store_true")

    args = pa.parse_args()

    cap = cv2.VideoCapture(args.input)
    if not cap.isOpened():
        raise SystemExit("âŒ æ‰“ä¸å¼€è¾“å…¥æ–‡ä»¶")

    src_fps = cap.get(cv2.CAP_PROP_FPS) or 30
    every = int(round(src_fps / args.fps))
    
    if args.full_duration:
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        grab_max = total_frames
        actual_duration = total_frames / src_fps
        print(f"ç¼–ç æ•´ä¸ªè§†é¢‘: {total_frames} å¸§ï¼Œæ—¶é•¿ {actual_duration:.2f} ç§’")
    else:
        grab_max = int(args.duration * src_fps)
        print(f"ç¼–ç æ—¶é•¿: {args.duration} ç§’ ({grab_max} å¸§)")

    strip_heights = calculate_strip_heights(HEIGHT, args.strip_count)
    print(f"æ¡å¸¦é…ç½®: {args.strip_count} ä¸ªæ¡å¸¦ï¼Œé«˜åº¦åˆ†åˆ«ä¸º: {strip_heights}")
    print(f"ç æœ¬é…ç½®: 4x4å—ç è¡¨{args.codebook_4x4_size}é¡¹, 2x2å—ç è¡¨{args.codebook_2x2_size}é¡¹")
    if args.dither:
        print(f"ğŸ¨ å·²å¯ç”¨æŠ–åŠ¨ç®—æ³•ï¼ˆè›‡å½¢æ‰«æï¼‰")
    
    frames = []
    idx = 0
    print("æ­£åœ¨æå–å¸§...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=args.threads) as executor:
        while idx < grab_max:
            ret, frm = cap.read()
            if not ret:
                break
            if idx % every == 0:
                frm = cv2.resize(frm, (WIDTH, HEIGHT), cv2.INTER_AREA)
                # if args.dither:
                #     frm = apply_dither_optimized(frm)
                strip_y_list = []
                y = 0
                for strip_height in strip_heights:
                    strip_y_list.append((frm, y, strip_height))
                    y += strip_height
                future_to_idx = {
                    executor.submit(pack_yuv420_strip, *args): i
                    for i, args in enumerate(strip_y_list)
                }
                frame_strips = [None] * len(strip_y_list)
                for future in concurrent.futures.as_completed(future_to_idx):
                    i = future_to_idx[future]
                    frame_strips[i] = future.result()
                frames.append(frame_strips)
                
                if len(frames) % 30 == 0:
                    print(f"  å·²æå– {len(frames)} å¸§")
            idx += 1
    cap.release()

    if not frames:
        raise SystemExit("âŒ æ²¡æœ‰ä»»ä½•å¸§è¢«é‡‡æ ·")

    print(f"æ€»å…±æå–äº† {len(frames)} å¸§")

    # ç”Ÿæˆç è¡¨
    gop_codebooks = generate_gop_codebooks_with_4x4_blocks(
        frames, args.strip_count, args.i_frame_interval, 
        args.variance_threshold, args.diff_threshold, args.distortion_threshold,
        args.codebook_4x4_size, args.codebook_2x2_size,
        args.kmeans_max_iter, args.i_frame_weight
    )

    # ç¼–ç æ‰€æœ‰å¸§
    print("æ­£åœ¨ç¼–ç å¸§...")
    encoded_frames = []
    frame_offsets = []
    current_offset = 0
    prev_strips = [None] * args.strip_count
    
    for frame_idx, current_strips in enumerate(frames):
        frame_offsets.append(current_offset)
        
        # æ‰¾åˆ°å½“å‰GOP
        gop_start = (frame_idx // args.i_frame_interval) * args.i_frame_interval
        gop_data = gop_codebooks[gop_start]
        
        frame_data = bytearray()
        
        for strip_idx, current_strip in enumerate(current_strips):
            strip_gop_data = gop_data[strip_idx]
            codebook_4x4 = strip_gop_data['codebook_4x4']
            codebook_2x2 = strip_gop_data['codebook_2x2']
            
            # æ‰¾åˆ°å½“å‰å¸§çš„åˆ†ç±»ä¿¡æ¯
            block_types = None
            block_4x4_indices = None
            for fid, bt, bbi in strip_gop_data['block_types_list']:
                if fid == frame_idx:
                    block_types = bt
                    block_4x4_indices = bbi
                    break
            
            force_i_frame = (frame_idx % args.i_frame_interval == 0) or frame_idx == 0
            
            if force_i_frame or prev_strips[strip_idx] is None:
                strip_data = encode_strip_i_frame_with_4x4_blocks(
                    current_strip, codebook_4x4, codebook_2x2, 
                    block_types, block_4x4_indices
                )
                is_i_frame = True
                
                # è®¡ç®—ç æœ¬å’Œç´¢å¼•å¤§å°
                codebook_4x4_size = args.codebook_4x4_size * BYTES_PER_4X4_BLOCK
                codebook_2x2_size = args.codebook_2x2_size * BYTES_PER_2X2_BLOCK
                index_size = len(strip_data) - 1 - codebook_4x4_size - codebook_2x2_size
                
                encoding_stats.add_i_frame(
                    strip_idx, len(strip_data), 
                    is_forced=force_i_frame,
                    codebook_size=codebook_4x4_size + codebook_2x2_size,
                    index_size=max(0, index_size)
                )
            else:
                strip_data, is_i_frame, used_zones, updates_4x4, updates_2x2 = encode_strip_p_frame_with_4x4_blocks(
                    current_strip, prev_strips[strip_idx],
                    codebook_4x4, codebook_2x2, block_types, block_4x4_indices,
                    args.diff_threshold, args.force_i_threshold, args.variance_threshold, args.distortion_threshold
                )
                
                if is_i_frame:
                    codebook_4x4_size = args.codebook_4x4_size * BYTES_PER_4X4_BLOCK
                    codebook_2x2_size = args.codebook_2x2_size * BYTES_PER_2X2_BLOCK
                    index_size = len(strip_data) - 1 - codebook_4x4_size - codebook_2x2_size
                    
                    encoding_stats.add_i_frame(
                        strip_idx, len(strip_data), 
                        is_forced=False,
                        codebook_size=codebook_4x4_size + codebook_2x2_size,
                        index_size=max(0, index_size)
                    )
                else:
                    total_updates = updates_4x4 + updates_2x2
                    
                    encoding_stats.add_p_frame(
                        strip_idx, len(strip_data), total_updates, used_zones,
                        updates_4x4, updates_2x2
                    )
            
            frame_data.extend(struct.pack('<H', len(strip_data)))
            frame_data.extend(strip_data)
            
            prev_strips[strip_idx] = current_strip.copy() if current_strip.size > 0 else None
        
        encoded_frames.append(bytes(frame_data))
        current_offset += len(frame_data)
        
        if frame_idx % 30 == 0 or frame_idx == len(frames) - 1:
            print(f"  å·²ç¼–ç  {frame_idx + 1}/{len(frames)} å¸§")
    
    all_data = b''.join(encoded_frames)
    
    write_header(pathlib.Path(args.out).with_suffix(".h"), len(frames), len(all_data), 
                args.strip_count, strip_heights, args.codebook_4x4_size, args.codebook_2x2_size)
    write_source(pathlib.Path(args.out).with_suffix(".c"), all_data, frame_offsets, strip_heights)
    
    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    encoding_stats.print_summary(len(frames), len(all_data))

def write_header(path_h: pathlib.Path, frame_cnt: int, total_bytes: int, strip_count: int, 
                strip_heights: list, codebook_4x4_size: int, codebook_2x2_size: int):
    guard = "VIDEO_DATA_H"
    
    with path_h.open("w", encoding="utf-8") as f:
        f.write(textwrap.dedent(f"""\
            #ifndef {guard}
            #define {guard}

            #define VIDEO_FRAME_COUNT   {frame_cnt}
            #define VIDEO_WIDTH         {WIDTH}
            #define VIDEO_HEIGHT        {HEIGHT}
            #define VIDEO_TOTAL_BYTES   {total_bytes}
            #define VIDEO_STRIP_COUNT   {strip_count}
            #define CODEBOOK_4X4_SIZE {codebook_4x4_size}
            #define CODEBOOK_2X2_SIZE {codebook_2x2_size}
            #define EFFECTIVE_UNIFIED_CODEBOOK_SIZE {EFFECTIVE_UNIFIED_CODEBOOK_SIZE}

            #define BLOCK_4X4_MARKER {BLOCK_4X4_MARKER}
            
            // å¸§ç±»å‹å®šä¹‰
            #define FRAME_TYPE_I        0x00
            #define FRAME_TYPE_P        0x01
            
            // å—å‚æ•°
            #define BLOCK_WIDTH         2
            #define BLOCK_HEIGHT        2
            #define BYTES_PER_2X2_BLOCK     7
            #define BYTES_PER_4X4_BLOCK 28
            #define SUPER_BLOCK_SIZE    8

            // æ¡å¸¦é«˜åº¦æ•°ç»„
            extern const unsigned char strip_heights[VIDEO_STRIP_COUNT];
            
            extern const unsigned char video_data[VIDEO_TOTAL_BYTES];
            extern const unsigned int frame_offsets[VIDEO_FRAME_COUNT];

            #endif // {guard}
            """))

def write_source(path_c: pathlib.Path, data: bytes, frame_offsets: list, strip_heights: list):
    with path_c.open("w", encoding="utf-8") as f:
        f.write('#include "video_data.h"\n\n')
        

        
        f.write("const unsigned char strip_heights[] = {\n")
        f.write("    " + ', '.join(map(str, strip_heights)) + "\n")
        f.write("};\n\n")
        
        f.write("const unsigned int frame_offsets[] = {\n")
        for i in range(0, len(frame_offsets), 8):
            chunk = ', '.join(f"{offset}" for offset in frame_offsets[i:i+8])
            f.write("    " + chunk + ",\n")
        f.write("};\n\n")
        
        f.write("const unsigned char video_data[] = {\n")
        per_line = 16
        for i in range(0, len(data), per_line):
            chunk = ', '.join(f"0x{v:02X}" for v in data[i:i+per_line])
            f.write("    " + chunk + ",\n")
        f.write("};\n")

def generate_codebook(blocks_data: np.ndarray, codebook_size: int, max_iter: int = 100) -> tuple:
    """ä½¿ç”¨K-Meansèšç±»ç”Ÿæˆç è¡¨"""
    if len(blocks_data) == 0:
        return np.zeros((codebook_size, BYTES_PER_2X2_BLOCK), dtype=np.uint8), 0
    
    if blocks_data.ndim > 2:
        blocks_data = blocks_data.reshape(-1, BYTES_PER_2X2_BLOCK)
    
    # ç§»é™¤å»é‡æ“ä½œï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œèšç±»
    # è¿™æ ·K-Meanså¯ä»¥åŸºäºæ•°æ®çš„çœŸå®åˆ†å¸ƒï¼ˆåŒ…æ‹¬é¢‘æ¬¡ï¼‰è¿›è¡Œæ›´å¥½çš„èšç±»
    effective_size = min(len(blocks_data), codebook_size)
    
    if len(blocks_data) <= codebook_size:
        # å¦‚æœæ•°æ®é‡å°äºç æœ¬å¤§å°ï¼Œéœ€è¦å»é‡é¿å…é‡å¤
        blocks_as_tuples = [tuple(block) for block in blocks_data]
        unique_tuples = list(set(blocks_as_tuples))
        unique_blocks = np.array(unique_tuples, dtype=np.uint8)
        
        codebook = np.zeros((codebook_size, BYTES_PER_2X2_BLOCK), dtype=np.uint8)
        codebook[:len(unique_blocks)] = unique_blocks
        if len(unique_blocks) > 0:
            for i in range(len(unique_blocks), codebook_size):
                codebook[i] = unique_blocks[-1]
        return codebook, len(unique_blocks)
    
    # å¯¹äºå¤§æ•°æ®é›†ï¼Œç›´æ¥è¿›è¡ŒK-Meansèšç±»
    kmeans = MiniBatchKMeans(
        n_clusters=codebook_size,
        random_state=42,
        batch_size=min(1000, len(blocks_data)),
        max_iter=max_iter,
        n_init=3
    )
    blocks_for_clustering = convert_blocks_for_clustering(blocks_data)
    kmeans.fit(blocks_for_clustering)
    codebook = convert_codebook_from_clustering(kmeans.cluster_centers_)
    
    return codebook, codebook_size

def convert_blocks_for_clustering(blocks_data: np.ndarray) -> np.ndarray:
    """å°†å—æ•°æ®è½¬æ¢ä¸ºæ­£ç¡®çš„èšç±»æ ¼å¼"""
    if len(blocks_data) == 0:
        return blocks_data.astype(np.float32)
    
    if blocks_data.ndim > 2:
        blocks_data = blocks_data.reshape(-1, BYTES_PER_2X2_BLOCK)
    
    blocks_float = blocks_data.astype(np.float32)
    
    for i in range(4, BYTES_PER_2X2_BLOCK):
        blocks_float[:, i] = blocks_data[:, i].view(np.int8).astype(np.float32)
    
    return blocks_float

def convert_codebook_from_clustering(codebook_float: np.ndarray) -> np.ndarray:
    """å°†èšç±»ç»“æœè½¬æ¢å›æ­£ç¡®çš„å—æ ¼å¼"""
    codebook = np.zeros_like(codebook_float, dtype=np.uint8)
    
    codebook[:, 0:4] = np.clip(codebook_float[:, 0:4].round(), 0, 255).astype(np.uint8)
    
    for i in range(4, BYTES_PER_2X2_BLOCK):
        clipped_values = np.clip(codebook_float[:, i].round(), -128, 127).astype(np.int8)
        codebook[:, i] = clipped_values.view(np.uint8)
    
    return codebook

def calculate_distortion_sad(original_blocks: list, reconstructed_blocks: list) -> float:
    """è®¡ç®—å¤±çœŸåº¦é‡ - SAD (Sum of Absolute Differences)"""
    if len(original_blocks) != len(reconstructed_blocks):
        return float('inf')
    
    total_sad = 0.0
    for orig, recon in zip(original_blocks, reconstructed_blocks):
        # Yåˆ†é‡çš„SADï¼ˆéœ€è¦ä¹˜2è¿˜åŸï¼‰
        y_orig = orig[:4].astype(np.float32) * 2.0  # è¿˜åŸYåˆ†é‡
        y_recon = recon[:4].astype(np.float32) * 2.0  # è¿˜åŸYåˆ†é‡
        y_sad = np.sum(np.abs(y_orig - y_recon))
        
        # CrCbåˆ†é‡çš„SADï¼ˆæœ‰ç¬¦å·æ•°è½¬æ¢ï¼‰
        chroma_orig = orig[4:7].view(np.int8).astype(np.float32)  # d_r, d_g, d_b
        chroma_recon = recon[4:7].view(np.int8).astype(np.float32)
        chroma_sad = np.sum(np.abs(chroma_orig - chroma_recon))
        
        # å¯ä»¥è°ƒæ•´æƒé‡ï¼Œè¿™é‡ŒYå’Œè‰²åº¦ç­‰æƒé‡
        total_sad += y_sad + chroma_sad
    
    return total_sad / len(original_blocks)  # å¹³å‡SAD

# é»˜è®¤ä½¿ç”¨SAD
calculate_distortion = calculate_distortion_sad

def generate_unified_codebook_simplified(small_blocks: list, 
                                       codebook_size: int = EFFECTIVE_UNIFIED_CODEBOOK_SIZE,
                                       kmeans_max_iter: int = 100) -> np.ndarray:
    """ç”Ÿæˆ2x2å°å—çš„ç»Ÿä¸€ç è¡¨ï¼ˆ254é¡¹ï¼Œé¿å…0xFEï¼‰"""
    if small_blocks:
        blocks_array = np.array(small_blocks)
        codebook, _ = generate_codebook(blocks_array, codebook_size, kmeans_max_iter)
        
        # åˆ›å»º254é¡¹ç è¡¨
        full_codebook = np.zeros((codebook_size, BYTES_PER_2X2_BLOCK), dtype=np.uint8)
        actual_size = min(len(codebook), codebook_size)
        full_codebook[:actual_size] = codebook[:actual_size]
        
        # å¡«å……å‰©ä½™é¡¹
        if actual_size > 0:
            for i in range(actual_size, codebook_size):
                full_codebook[i] = full_codebook[actual_size - 1]
    else:
        full_codebook = np.zeros((codebook_size, BYTES_PER_2X2_BLOCK), dtype=np.uint8)
    
    return full_codebook

@njit
def compute_block_differences_numba(current_flat, prev_flat, blocks_h, blocks_w):
    """NumbaåŠ é€Ÿçš„å—å·®å¼‚è®¡ç®—"""
    block_diffs = np.zeros((blocks_h, blocks_w), dtype=np.float64)
    
    for i in range(blocks_h * blocks_w):
        y_diff_sum = 0.0
        for j in range(4):  # åªè®¡ç®—Yåˆ†é‡å·®å¼‚
            current_val = int(current_flat[i, j])
            prev_val = int(prev_flat[i, j])
            if current_val >= prev_val:
                diff = current_val - prev_val
            else:
                diff = prev_val - current_val
            y_diff_sum += diff
        block_diffs[i // blocks_w, i % blocks_w] = y_diff_sum / 4.0
    
    return block_diffs

class EncodingStats:
    """ç¼–ç ç»Ÿè®¡ç±» - ä¿®å¤ç»Ÿè®¡é—®é¢˜"""
    def __init__(self):
        # å¸§ç»Ÿè®¡
        self.total_frames_processed = 0
        self.total_i_frames = 0
        self.forced_i_frames = 0
        self.threshold_i_frames = 0
        self.total_p_frames = 0
        
        # å¤§å°ç»Ÿè®¡
        self.total_i_frame_bytes = 0
        self.total_p_frame_bytes = 0
        self.total_4x4_codebook_bytes = 0
        self.total_2x2_codebook_bytes = 0
        self.total_index_bytes = 0
        self.total_p_overhead_bytes = 0
        
        # å—ç±»å‹ç»Ÿè®¡ - ä¿®å¤
        self.block_4x4_count = 0
        self.block_2x2_count = 0
        
        # På¸§å—æ›´æ–°ç»Ÿè®¡ - æ–°å¢è¯¦ç»†ç»Ÿè®¡
        self.p_frame_updates = []
        self.zone_usage = defaultdict(int)
        self.detail_update_count = 0
        self.block_4x4_update_count = 0
        self.block_2x2_update_count = 0
        self.detail_update_bytes = 0  # çº¹ç†å—æ›´æ–°å­—èŠ‚æ•°
        self.block_4x4_update_bytes = 0  # å¤§å—æ›´æ–°å­—èŠ‚æ•°
        
        # æ¡å¸¦ç»Ÿè®¡
        self.strip_stats = defaultdict(lambda: {
            'i_frames': 0, 'p_frames': 0, 
            'i_bytes': 0, 'p_bytes': 0
        })
    
    def add_i_frame(self, strip_idx, size_bytes, is_forced=True, codebook_size=0, index_size=0):
        self.total_frames_processed += 1
        self.total_i_frames += 1
        if is_forced:
            self.forced_i_frames += 1
        else:
            self.threshold_i_frames += 1
        
        self.total_i_frame_bytes += size_bytes
        
        # ä¿®å¤ç æœ¬ç»Ÿè®¡ - åˆ†åˆ«è®¡ç®—4x4å’Œ2x2ç æœ¬
        codebook_4x4_bytes = DEFAULT_4X4_CODEBOOK_SIZE * BYTES_PER_4X4_BLOCK
        codebook_2x2_bytes = EFFECTIVE_UNIFIED_CODEBOOK_SIZE * BYTES_PER_2X2_BLOCK
        self.total_4x4_codebook_bytes += codebook_4x4_bytes
        self.total_2x2_codebook_bytes += codebook_2x2_bytes
        
        # ç´¢å¼•å¤§å° = æ€»å¤§å° - å¸§ç±»å‹æ ‡è®° - ä¸¤ä¸ªç æœ¬å¤§å°
        actual_index_size = size_bytes - 1 - codebook_4x4_bytes - codebook_2x2_bytes
        self.total_index_bytes += max(0, actual_index_size)
        
        self.strip_stats[strip_idx]['i_frames'] += 1
        self.strip_stats[strip_idx]['i_bytes'] += size_bytes
    
    def add_p_frame(self, strip_idx, size_bytes, updates_count, zone_count, 
               updates_4x4=0, updates_2x2=0):  # ä¿®æ”¹å‚æ•°åå’Œé¡ºåº
        self.total_frames_processed += 1
        self.total_p_frames += 1
        self.total_p_frame_bytes += size_bytes
        self.p_frame_updates.append(updates_count)
        self.zone_usage[zone_count] += 1
        
        # På¸§å¼€é”€ï¼šå¸§ç±»å‹(1) + bitmap(2) + æ¯ä¸ªåŒºåŸŸçš„è®¡æ•°(2*zones)
        overhead = 3 + zone_count * 2  # ç°åœ¨åªæœ‰2ç§å—ç±»å‹
        self.total_p_overhead_bytes += overhead
        
        # è¯¦ç»†æ›´æ–°ç»Ÿè®¡
        self.detail_update_count += updates_2x2
        self.block_4x4_update_count += updates_4x4  # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å€¼
        
        # è®¡ç®—æ›´æ–°æ•°æ®å­—èŠ‚æ•°
        detail_bytes = updates_2x2 * 17  # 1å­—èŠ‚ä½ç½® + 16å­—èŠ‚ç´¢å¼•
        block_4x4_bytes = updates_4x4 * 5  # 1å­—èŠ‚ä½ç½® + 4å­—èŠ‚ç´¢å¼•
        self.detail_update_bytes += detail_bytes
        self.block_4x4_update_bytes += block_4x4_bytes
        
        self.strip_stats[strip_idx]['p_frames'] += 1
        self.strip_stats[strip_idx]['p_bytes'] += size_bytes
    
    def add_block_type_stats(self, block_4x4s, block_2x2s):
        self.block_4x4_count += block_4x4s
        self.block_2x2_count += block_2x2s
    
    def print_summary(self, total_frames, total_bytes):
        print(f"\nğŸ“Š ç¼–ç ç»Ÿè®¡æŠ¥å‘Š")
        print(f"=" * 60)
        
        # è®¡ç®—æ¡å¸¦çº§åˆ«çš„ç»Ÿè®¡
        strip_count = len(self.strip_stats) if self.strip_stats else 1
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ¬ å¸§ç»Ÿè®¡:")
        print(f"   è§†é¢‘å¸§æ•°: {total_frames}")
        print(f"   æ¡å¸¦æ€»æ•°: {strip_count}")
        print(f"   å¤„ç†çš„æ¡å¸¦å¸§: {self.total_frames_processed}")
        print(f"   Iå¸§æ¡å¸¦: {self.total_i_frames} ({self.total_i_frames/self.total_frames_processed*100:.1f}%)")
        print(f"     - å¼ºåˆ¶Iå¸§: {self.forced_i_frames}")
        print(f"     - è¶…é˜ˆå€¼Iå¸§: {self.threshold_i_frames}")
        print(f"   På¸§æ¡å¸¦: {self.total_p_frames} ({self.total_p_frames/self.total_frames_processed*100:.1f}%)")
        
        # å¤§å°ç»Ÿè®¡
        print(f"\nğŸ’¾ ç©ºé—´å ç”¨:")
        print(f"   æ€»å¤§å°: {total_bytes:,} bytes ({total_bytes/1024:.1f} KB)")
        print(f"   Iå¸§æ•°æ®: {self.total_i_frame_bytes:,} bytes ({self.total_i_frame_bytes/total_bytes*100:.1f}%)")
        print(f"   På¸§æ•°æ®: {self.total_p_frame_bytes:,} bytes ({self.total_p_frame_bytes/total_bytes*100:.1f}%)")
        
        if self.total_i_frames > 0:
            print(f"   å¹³å‡Iå¸§å¤§å°: {self.total_i_frame_bytes/self.total_i_frames:.1f} bytes")
        if self.total_p_frames > 0:
            print(f"   å¹³å‡På¸§å¤§å°: {self.total_p_frame_bytes/self.total_p_frames:.1f} bytes")
        
        # æ•°æ®æ„æˆç»Ÿè®¡
        print(f"\nğŸ¨ æ•°æ®æ„æˆ:")
        print(f"   4x4å—ç æœ¬æ•°æ®: {self.total_4x4_codebook_bytes:,} bytes ({self.total_4x4_codebook_bytes/total_bytes*100:.1f}%)")
        print(f"   2x2å—ç æœ¬æ•°æ®: {self.total_2x2_codebook_bytes:,} bytes ({self.total_2x2_codebook_bytes/total_bytes*100:.1f}%)")
        print(f"   Iå¸§ç´¢å¼•: {self.total_index_bytes:,} bytes ({self.total_index_bytes/total_bytes*100:.1f}%)")
        
        # På¸§æ•°æ®æ„æˆ
        p_frame_data_bytes = self.total_p_frame_bytes - self.total_p_overhead_bytes
        print(f"   På¸§æ›´æ–°æ•°æ®: {p_frame_data_bytes:,} bytes ({p_frame_data_bytes/total_bytes*100:.1f}%)")
        print(f"     - 2x2å—æ›´æ–°: {self.detail_update_bytes:,} bytes ({self.detail_update_bytes/total_bytes*100:.1f}%)")
        print(f"     - 4x4å—æ›´æ–°: {self.block_4x4_update_bytes:,} bytes ({self.block_4x4_update_bytes/total_bytes*100:.1f}%)")
        print(f"   På¸§å¼€é”€: {self.total_p_overhead_bytes:,} bytes ({self.total_p_overhead_bytes/total_bytes*100:.1f}%)")
        
        # å—ç±»å‹ç»Ÿè®¡
        print(f"\nğŸ§© å—ç±»å‹åˆ†å¸ƒ:")
        total_block_types = self.block_4x4_count + self.block_2x2_count
        if total_block_types > 0:
            print(f"   4x4å—: {self.block_4x4_count} ä¸ª ({self.block_4x4_count/total_block_types*100:.1f}%)")
            print(f"   2x2å—: {self.block_2x2_count} ä¸ª ({self.block_2x2_count/total_block_types*100:.1f}%)")
        
        # På¸§æ›´æ–°ç»Ÿè®¡
        if self.p_frame_updates:
            avg_updates = statistics.mean(self.p_frame_updates)
            median_updates = statistics.median(self.p_frame_updates)
            max_updates = max(self.p_frame_updates)
            min_updates = min(self.p_frame_updates)
            
            print(f"\nâš¡ På¸§æ›´æ–°åˆ†æ:")
            print(f"   å¹³å‡æ›´æ–°å—æ•°: {avg_updates:.1f}")
            print(f"   ä¸­ä½æ•°æ›´æ–°å—æ•°: {median_updates}")
            print(f"   æœ€å¤§æ›´æ–°å—æ•°: {max_updates}")
            print(f"   æœ€å°æ›´æ–°å—æ•°: {min_updates}")
            print(f"   2x2å—æ›´æ–°æ€»æ•°: {self.detail_update_count:,}")
            print(f"   4x4å—æ›´æ–°æ€»æ•°: {self.block_4x4_update_count:,}")
        
        # åŒºåŸŸä½¿ç”¨ç»Ÿè®¡
        if self.zone_usage:
            print(f"\nğŸ—ºï¸  åŒºåŸŸä½¿ç”¨åˆ†å¸ƒ:")
            for zone_count in sorted(self.zone_usage.keys()):
                frames_count = self.zone_usage[zone_count]
                if self.total_p_frames > 0:
                    print(f"   {zone_count}ä¸ªåŒºåŸŸ: {frames_count}æ¬¡ ({frames_count/self.total_p_frames*100:.1f}%)")
        
        # æ¡å¸¦ç»Ÿè®¡
        print(f"\nğŸ“ æ¡å¸¦ç»Ÿè®¡:")
        for strip_idx in sorted(self.strip_stats.keys()):
            stats = self.strip_stats[strip_idx]
            total_strip_frames = stats['i_frames'] + stats['p_frames']
            total_strip_bytes = stats['i_bytes'] + stats['p_bytes']
            if total_strip_frames > 0:
                print(f"   æ¡å¸¦{strip_idx}: {total_strip_frames}å¸§, {total_strip_bytes:,}bytes, "
                      f"å¹³å‡{total_strip_bytes/total_strip_frames:.1f}bytes/å¸§")
        
        # å‹ç¼©æ•ˆç‡
        raw_size = total_frames * WIDTH * HEIGHT * 2
        compression_ratio = raw_size / total_bytes if total_bytes > 0 else 0
        print(f"\nğŸ“ˆ å‹ç¼©æ•ˆç‡:")
        print(f"   åŸå§‹å¤§å°ä¼°ç®—: {raw_size:,} bytes ({raw_size/1024/1024:.1f} MB)")
        print(f"   å‹ç¼©æ¯”: {compression_ratio:.1f}:1")
        print(f"   å‹ç¼©ç‡: {(1-total_bytes/raw_size)*100:.1f}%")

# å…¨å±€ç»Ÿè®¡å¯¹è±¡
encoding_stats = EncodingStats()

if __name__ == "__main__":
    main()